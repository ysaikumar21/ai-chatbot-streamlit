{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3sOL4U27-UW",
        "outputId": "2a99f96c-d909-4228-9cb4-d15cb09bb59b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:39:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Training Complete! Accuracy: 0.500\n",
            "✅ Model & vectorizer saved! Ready for chatbot deployment.\n",
            "Vajra.AI: Hello! Type 'quit' to exit.\n",
            "You: hi\n",
            "Vajra.AI: Hello! Welcome to Social Prachar Institute. How can I assist you today?\n",
            "You: q\n",
            "Vajra.AI: Good day! I’m Vajra.AI, your guide to the Social Prachar Institute. What would you like to know?\n",
            "You: d\n",
            "Vajra.AI: Hello! Welcome to Social Prachar Institute. How can I assist you today?\n",
            "You: df\n",
            "Vajra.AI: Good day! I’m Vajra.AI, your guide to the Social Prachar Institute. What would you like to know?\n",
            "You: quit\n",
            "Vajra.AI: Bye! See you again.\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 1: Install Dependencies\n",
        "!pip install nltk scikit-learn numpy pandas xgboost\n",
        "\n",
        "# ✅ Step 2: Import Libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ✅ Step 3: Download NLTK Data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# ✅ Step 4: Initialize Lemmatizer & Stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# ✅ Step 5: Define Updated Intents (More Examples)\n",
        "intents = [\n",
        "    {\n",
        "        \"intent\": \"greetings\",\n",
        "        \"patterns\": [\"Hello\", \"Hi\", \"Good day\", \"Hey\", \"How are you?\", \"Good morning\", \"Hi there\", \"Greetings\", \"Hey bot\"],\n",
        "        \"responses\": [\n",
        "            \"Hello! Welcome to Social Prachar Institute. How can I assist you today?\",\n",
        "            \"Hi there! How can I help you with your queries about our courses?\",\n",
        "            \"Good day! I’m Vajra.AI, your guide to the Social Prachar Institute. What would you like to know?\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"intent\": \"farewells\",\n",
        "        \"patterns\": [\"Goodbye\", \"Bye\", \"Thank you\", \"See you later\", \"Take care\", \"Farewell\", \"Thanks\", \"See you soon\"],\n",
        "        \"responses\": [\n",
        "            \"Thank you for visiting! Have a great day!\",\n",
        "            \"It was my pleasure to assist you. Take care and good luck with your learning journey!\",\n",
        "            \"Goodbye, and feel free to come back if you have more questions!\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"intent\": \"fee_structure\",\n",
        "        \"patterns\": [\"How much does the course cost?\", \"What are the fees?\", \"Tell me the course fees.\", \"Price of Data Science?\", \"Tuition fees?\"],\n",
        "        \"responses\": [\n",
        "            \"The fee for Data Science is 50k, and other courses are 30k.\",\n",
        "            \"Our courses are priced as follows: Data Science - 50k, Data Analytics - 30k, Python Full Stack - 30k, Java Full Stack - 30k, AWS Developer - 30k.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"intent\": \"course_info\",\n",
        "        \"patterns\": [\"What courses do you offer?\", \"Tell me about courses\", \"List all courses\", \"Available programs?\", \"Which subjects?\", \"Training programs?\", \"Social Prachar courses?\"],\n",
        "        \"responses\": [\n",
        "            \"We offer Data Science, Data Analytics, Python Full Stack, Java Full Stack, and AWS Developer courses.\",\n",
        "            \"Our courses include Data Science & AI, Data Analytics, Python Full Stack, Java Full Stack, and AWS Developer. You can learn more on our website.\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# ✅ Step 6: Preprocess Data\n",
        "def preprocess_sentence(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "    tokens = [lemmatizer.lemmatize(word, pos=\"v\") for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "class_names = []\n",
        "\n",
        "for intent in intents:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        processed_sentence = preprocess_sentence(pattern)\n",
        "        training_sentences.append(processed_sentence)\n",
        "        training_labels.append(intent[\"intent\"])\n",
        "\n",
        "    if intent[\"intent\"] not in class_names:\n",
        "        class_names.append(intent[\"intent\"])\n",
        "\n",
        "# ✅ Step 7: Feature Extraction (Optimized TF-IDF)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=7000, min_df=2)\n",
        "X = vectorizer.fit_transform(training_sentences).toarray()\n",
        "\n",
        "# ✅ Step 8: Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(training_labels)\n",
        "\n",
        "# ✅ Step 9: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) # Increased test_size to 0.2\n",
        "\n",
        "# ✅ Step 10: Train **XGBoost Classifier** (Higher Accuracy)\n",
        "xgb_model = XGBClassifier(n_estimators=500, max_depth=10, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Step 11: Evaluate the Model\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'✅ Model Training Complete! Accuracy: {accuracy:.3f}')\n",
        "\n",
        "# ✅ Step 12: Save Model & Vectorizer\n",
        "with open(\"chatbot_model.pkl\", \"wb\") as model_file:\n",
        "    pickle.dump(xgb_model, model_file)\n",
        "\n",
        "with open(\"vectorizer.pkl\", \"wb\") as vec_file:\n",
        "    pickle.dump(vectorizer, vec_file)\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"wb\") as encoder_file:\n",
        "    pickle.dump(label_encoder, encoder_file)\n",
        "\n",
        "print(\"✅ Model & vectorizer saved! Ready for chatbot deployment.\")\n",
        "\n",
        "# ✅ Step 13: Load Model for Deployment\n",
        "def load_model():\n",
        "    with open(\"chatbot_model.pkl\", \"rb\") as model_file:\n",
        "        model = pickle.load(model_file)\n",
        "    with open(\"vectorizer.pkl\", \"rb\") as vec_file:\n",
        "        vectorizer = pickle.load(vec_file)\n",
        "    with open(\"label_encoder.pkl\", \"rb\") as encoder_file:\n",
        "        label_encoder = pickle.load(encoder_file)\n",
        "    return model, vectorizer, label_encoder\n",
        "\n",
        "xgb_model, vectorizer, label_encoder = load_model()\n",
        "\n",
        "# ✅ Step 14: Prediction Function (Higher Confidence Threshold)\n",
        "def predict_intent(user_input):\n",
        "    user_input_tokens = preprocess_sentence(user_input)\n",
        "    input_vector = vectorizer.transform([user_input_tokens]).toarray()\n",
        "    prediction_prob = xgb_model.predict_proba(input_vector)\n",
        "\n",
        "    predicted_class_index = np.argmax(prediction_prob)\n",
        "    confidence = np.max(prediction_prob)\n",
        "\n",
        "    if confidence < 0.2:\n",
        "        return \"I'm not certain. Could you clarify your question?\"\n",
        "\n",
        "    prediction = label_encoder.classes_[predicted_class_index]\n",
        "\n",
        "    for intent in intents:\n",
        "        if intent['intent'] == prediction:\n",
        "            return random.choice(intent['responses'])\n",
        "\n",
        "    return \"Sorry, I didn’t understand that. Could you please rephrase?\"\n",
        "\n",
        "# ✅ Step 15: Chatbot Interaction\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Vajra.AI: Hello! Type 'quit' to exit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"Vajra.AI: Bye! See you again.\")\n",
        "            break\n",
        "        response = predict_intent(user_input)\n",
        "        print(f\"Vajra.AI: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MC_CJLry8HwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}